{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7107b9d-b3b3-4857-862a-868eab7a671b",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "This week, we will learn to implement artificial neural networks, another class of models that can be used in molecular property prediction. \n",
    "\n",
    "![](mldd_diagram_lab3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a217d",
   "metadata": {},
   "source": [
    "# Molecular graphs\n",
    "\n",
    "**Recap:** In mathematics, a graph is an object that consists of a set of vertices (nodes) connected with edges, i.e. $\\mathcal{G} = (V, E)$, where $V = \\{ v_i: i \\in \\{1, 2, \\dots, N \\} \\}$ and $E \\subseteq \\{ (v_i, v_j):\\, v_i,v_j \\in V \\}$.\n",
    "\n",
    "Molecular graphs are a special class of graphs, where besides nodes (denoting atoms) and edges (denoting chemical bonds), we have an additional information about atom types and sometimes also bond types. We can assume that we have an additional set of node/atom features encoded as a matrix $X$, where $X_{ij}$ is the $j$-th feature of the $i$-th atom. As atomic features, we can have one-hot encoded atom symbols (a vector containing zeros on all positions besides the position that corresponds to the atom symbol), the number of implicit hydrogens bonded with this atom, or the number of heavy neighbors (atoms other than hydrogens bonded to the given atom).\n",
    "\n",
    "Egdes/bonds can be encoded in two different ways. One method is to use an adjacency matrix $A$, where $A_{ij}=1$ if nodes/atoms $v_i$ nad $v_j$ are connected ($A_{ij}=0$ otherwise). In the case of sparse matrices, a more useful encoding is a list of pairs of connected atoms (a list of index pairs). This latter enocding is used by the PyTorch-Geometric library.\n",
    "\n",
    "In practice, a molecular graph can be described by two matrices: $X \\in \\mathbb{R}^{N \\times F}$ and $E \\in \\{0, 1,\\dots,N-1\\}^{2 \\times N}$, where $N$ is the number of atoms, and $F$ is the number of atomic features.\n",
    "\n",
    "![molecular graph](../../lectures/assets/mol_graph.png)\n",
    "\n",
    "**Exercise 2:** Create a molecular graph dataset using PyTorch-Geometric and the same data as in Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc58b6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:29] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tdc.single_pred.adme import ADME\n",
    "from tdc import Evaluator\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class Featurizer:\n",
    "    def __init__(self, y_column, smiles_col='Drug', **kwargs):\n",
    "        self.y_column = y_column\n",
    "        self.smiles_col = smiles_col\n",
    "        self.__dict__.update(kwargs)\n",
    "    \n",
    "    def __call__(self, df):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class ECFPFeaturizer(Featurizer):\n",
    "    def __init__(self, y_column, radius=2, length=1024, **kwargs):\n",
    "        self.radius = radius\n",
    "        self.length = length\n",
    "        super().__init__(y_column, **kwargs)\n",
    "    \n",
    "    def __call__(self, df):\n",
    "        fingerprints = []\n",
    "        labels = []\n",
    "        for i, row in df.iterrows():\n",
    "            y = row[self.y_column]\n",
    "            smiles = row[self.smiles_col]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, self.radius, nBits=self.length)\n",
    "            fingerprints.append(fp)\n",
    "            labels.append(y)\n",
    "        fingerprints = np.array(fingerprints)\n",
    "        labels = np.array(labels)\n",
    "        return fingerprints, labels\n",
    "\n",
    "data = ADME('Solubility_AqSolDB')\n",
    "split = data.get_split()\n",
    "rmse = Evaluator(name = 'RMSE')\n",
    "\n",
    "featurizer = ECFPFeaturizer(y_column='Y')\n",
    "X_train, y_train = featurizer(split['train'])\n",
    "X_valid, y_valid = featurizer(split['valid'])\n",
    "X_test, y_test = featurizer(split['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed7f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise ValueError(\"input {0} not in allowable set{1}:\".format(\n",
    "            x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "class GraphFeaturizer(Featurizer):\n",
    "    def __call__(self, df):\n",
    "        graphs = []\n",
    "        labels = []\n",
    "        for i, row in df.iterrows():\n",
    "            y = row[self.y_column]\n",
    "            smiles = row[self.smiles_col]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            \n",
    "            edges = []\n",
    "            for bond in mol.GetBonds():\n",
    "                edges.append((bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()))\n",
    "                edges.append((bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()))  # TODO: Add edges in both directions\n",
    "            edges = np.array(edges)\n",
    "            \n",
    "            nodes = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                results = one_of_k_encoding_unk(atom.GetSymbol(), ['C', 'O', 'N', 'S', 'Cl', 'F', 'I', 'Br'])  # TODO: Add atom features as a list, you can use one_of_k_encodings defined above\n",
    "                nodes.append(results)\n",
    "            nodes = np.array(nodes)\n",
    "            \n",
    "            graphs.append((nodes, edges.T))\n",
    "            labels.append(y)\n",
    "        labels = np.array(labels)\n",
    "        return [Data(\n",
    "            x=torch.FloatTensor(x), \n",
    "            edge_index=torch.LongTensor(edge_index), \n",
    "            y=torch.FloatTensor([y])\n",
    "        ) for ((x, edge_index), y) in zip(graphs, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609d4db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks OK!\n"
     ]
    }
   ],
   "source": [
    "featurizer = GraphFeaturizer('Y')\n",
    "graph = featurizer(split['test'].iloc[:1])[0]\n",
    "\n",
    "assert graph.x.ndim == 2, 'The atom features should be a matrix with dimensions (number of atoms) x (number of features)'\n",
    "assert graph.edge_index.ndim == 2, 'The edges should be represented as a matrix of atom pairs'\n",
    "assert graph.edge_index.shape[0] == 2, 'The first dimension should be 2 (we need atom pairs)'\n",
    "assert isinstance(graph.y, torch.FloatTensor) and graph.y.shape == (1,), 'The graph label should be assigned to the variable `y`'\n",
    "print('Looks OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566ac82-f64c-41de-a36d-25921f02c976",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between\">\n",
    "    <div style=\"width: 20%; display: inline-block; margin: 20px\">\n",
    "        <img src=\"../../assets/profile1.png\" width=\"100%\">\n",
    "    </div>\n",
    "    <div style=\"width: 60%; display: inline-block; margin: 20px\">\n",
    "        <p><strong>Nitro:</strong> Atoms possess several important properties that define their behavior in chemical systems. The <strong>atomic number</strong> of an atom signifies the number of protons in its nucleus, which determines its elemental identity and placement on the periodic table. <strong>Formal charge</strong> represents the charge assigned to an atom in a molecule or ion, calculated by considering the number of valence electrons and its bonding situation. <strong>Partial charge</strong> refers to the uneven distribution of electron density within a molecule, resulting in regions of slight positive or negative charge. <strong>Hybridization</strong> is a concept that describes the mixing of atomic orbitals to form hybrid orbitals, crucial for understanding molecular geometry and bonding patterns. These properties collectively influence an atom's reactivity, bonding behavior, and its role within chemical compounds, providing insight into the complex nature of molecular interactions.</p>\n",
    "    </div>\n",
    "</div>\n",
    "<div style=\"width: 80%; display: block; margin: 0 20px 0\">\n",
    "    <p>In typical druglike compounds, a diverse array of atom types can be found, each playing a crucial role in the compound's pharmacological activity. <strong>Carbon</strong> atoms are ubiquitous, forming the backbone of organic molecules and providing structural stability. <strong>Hydrogen</strong> atoms frequently accompany carbon, contributing to molecular stability and participating in various bonding interactions. <strong>Oxygen</strong> atoms are common, often found in functional groups such as hydroxyl (-OH) and carbonyl (C=O), influencing the compound's polarity and reactivity. <strong>Nitrogen</strong> atoms, present in amines and amides, contribute to the compound's basicity and ability to form hydrogen bonds. Additionally, <strong>sulfur</strong> atoms may appear in thiol (-SH) or sulfide (-S-) groups, introducing potential sites for redox reactions or metal binding. Halogens, such as <strong>fluorine</strong>, <strong>chlorine</strong>, <strong>bromine</strong>, and <strong>iodine</strong>, are also commonly encountered in druglike compounds, where they can serve as substituents or functional groups, imparting specific chemical properties and influencing the compound's biological activity and metabolic stability. These diverse atom types collectively contribute to the complex pharmacological properties of druglike compounds, influencing their efficacy, safety, and pharmacokinetic profiles.</p>\n",
    "    </div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93051f97",
   "metadata": {},
   "source": [
    "# Graph neural networks\n",
    "\n",
    "Graph neural networks (GNNs) can process graph representation given at the input to the model. A graph layer uses the input atom features and graph topology to calculate new atom representations, but the graph structure is not changed (the edges stay the same). We can use the calculated atom representations for **node classification**, or we can add a graph readout operation at the end to aggregate information from all nodes into one vector that describes the whole graph (e.g. we can use the average atom representation). The graph representation can be then processed by fully-connected layers for the **graph classification** task.\n",
    "\n",
    "\n",
    "## Message Passing Neural Networks (MPNN)\n",
    "\n",
    "MPNN is a general description of a graph neural network, and many graph neural network architectures can be matched with this description (including the ones listed below). In MPNN, **messages** $M$ from the neighboring atoms are retrieved to calculate a new atom representation via the **update** $U$ operation. This procedure is repeated a few times before we use **readout** $R$ to compute the graph representation.\n",
    "\n",
    "$$\n",
    "\\mathbf{m}_i^{t+1} = \\sum_{j\\in\\mathcal{N}(i)} M_t(\\mathbf{h}_i^t, \\mathbf{h}_j^t, \\mathbf{e}_{ij})\\\\\n",
    "\\mathbf{h}_i^{t+1} = U_t(\\mathbf{h}_i^t, \\mathbf{m}_i^{t+1}) \\\\\n",
    "\\hat{y} = R(\\{\\mathbf{h}_i^T \\, | \\, i \\in \\mathcal{G} \\})\n",
    "$$\n",
    "\n",
    "- **Graph Convolutional Networks (GCN)**\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{t+1} = W^T \\sum_{j\\in\\mathcal{N}(i)\\cup \\{i\\}} \\frac{e_{ij}}{\\sqrt{\\hat{d}_i \\hat{d}_j}} \\mathbf{h}_j^t\n",
    "$$\n",
    "\n",
    "- **Graph Isomorphism Networks (GIN)**\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{t+1} = W^T \\left( (1+\\varepsilon)\\mathbf{h}_i^t + \\sum_{j\\in\\mathcal{N}(i)} \\mathbf{h}_j^t \\right)\n",
    "$$\n",
    "\n",
    "- **GraphSAGE**\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{t+1} = W_1 \\mathbf{h}_i^t + W_2 \\frac{1}{|\\mathcal{N}(i)|} \\sum_{j\\in\\mathcal{N}(i)} \\mathbf{h}_j^t\n",
    "$$\n",
    "\n",
    "- **Graph Attention Networks (GAT)**\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{t+1} = \\sum_{j\\in\\mathcal{N}(i)\\cup \\{i\\}} \\alpha_{ij} W \\mathbf{h}_j^t,\\\\\n",
    "\\alpha_{ij} = \\frac{\\exp\\left( LeakyReLU(\\mathbf{a}[W\\mathbf{h}_i^t \\| W\\mathbf{h}_j^t])\\right)}{\\sum_{k\\in\\mathcal{N}(i) \\cup \\{i\\}}\\exp\\left( LeakyReLU(\\mathbf{a}[W\\mathbf{h}_i^t \\| W\\mathbf{h}_k^t])\\right)}\n",
    "$$\n",
    "\n",
    "**Exercise 3:** Use the molecular graphs prepared in the previous exercise to predict compound solubility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da98aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:33] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tdc.single_pred.adme import ADME\n",
    "from tdc import Evaluator\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class Featurizer:\n",
    "    def __init__(self, y_column, smiles_col='Drug', **kwargs):\n",
    "        self.y_column = y_column\n",
    "        self.smiles_col = smiles_col\n",
    "        self.__dict__.update(kwargs)\n",
    "    \n",
    "    def __call__(self, df):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class ECFPFeaturizer(Featurizer):\n",
    "    def __init__(self, y_column, radius=2, length=1024, **kwargs):\n",
    "        self.radius = radius\n",
    "        self.length = length\n",
    "        super().__init__(y_column, **kwargs)\n",
    "    \n",
    "    def __call__(self, df):\n",
    "        fingerprints = []\n",
    "        labels = []\n",
    "        for i, row in df.iterrows():\n",
    "            y = row[self.y_column]\n",
    "            smiles = row[self.smiles_col]\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, self.radius, nBits=self.length)\n",
    "            fingerprints.append(fp)\n",
    "            labels.append(y)\n",
    "        fingerprints = np.array(fingerprints)\n",
    "        labels = np.array(labels)\n",
    "        return fingerprints, labels\n",
    "\n",
    "data = ADME('Solubility_AqSolDB')\n",
    "split = data.get_split()\n",
    "rmse = Evaluator(name = 'RMSE')\n",
    "\n",
    "featurizer = ECFPFeaturizer(y_column='Y')\n",
    "X_train, y_train = featurizer(split['train'])\n",
    "X_valid, y_valid = featurizer(split['valid'])\n",
    "X_test, y_test = featurizer(split['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f6b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:34] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:37] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:37] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:37] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:37] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:37] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:37] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:23:38] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
    "\n",
    "\n",
    "# prepare data loaders\n",
    "batch_size = 64\n",
    "train_loader = GraphDataLoader(featurizer(split['train']), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = GraphDataLoader(featurizer(split['valid']), batch_size=batch_size)\n",
    "test_loader = GraphDataLoader(featurizer(split['test']), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50cb8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GraphNeuralNetwork(torch.nn.Module):  # TODO: assign hyperparameters to attributes and define the forward pass\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(in_channels=8, out_channels=hidden_size)\n",
    "        self.gcn2 = GCNConv(in_channels=hidden_size, out_channels=hidden_size)\n",
    "        self.gcn3 = GCNConv(in_channels=hidden_size, out_channels=hidden_size)\n",
    "        self.lin1 = torch.nn.Linear(in_features=hidden_size, out_features=1)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        y = self.gcn1(x, edge_index)\n",
    "        y = F.relu(y)\n",
    "        y = self.gcn2(y, edge_index)\n",
    "        y = F.relu(y)\n",
    "        y = self.gcn3(y, edge_index)\n",
    "        y = global_mean_pool(y, batch)\n",
    "        y = self.lin1(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be6c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f5a7e217344f80abd2dd245e1e9c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2a03fc67ee4a3dbbf9a129153dd1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "DataLoader found invalid type: '<class 'numpy.ndarray'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m model, df_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# evaluation\u001b[39;00m\n\u001b[1;32m     56\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predict(model, test_loader)\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, valid_loader, df_logs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     20\u001b[0m         x, edge_index, batch, y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch, data\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/torch_geometric/loader/dataloader.py:49\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)]\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader found invalid type: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(elem)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: DataLoader found invalid type: '<class 'numpy.ndarray'>'"
     ]
    }
   ],
   "source": [
    "df_logs = pd.DataFrame()\n",
    "\n",
    "def train(train_loader, valid_loader, df_logs):\n",
    "    # hyperparameters definition\n",
    "    hidden_size = 512\n",
    "    epochs = 10\n",
    "    learning_rate = 0.0001\n",
    "    \n",
    "    # model preparation\n",
    "    model = GraphNeuralNetwork(hidden_size)  # TODO: you can add more hyperparameters if needed\n",
    "    model.train()\n",
    "    \n",
    "    # training loop\n",
    "    optimizer = torch.optim.Adam(model.parameters()) # TODO: define an optimizer\n",
    "    loss_fn = torch.nn.MSELoss()  # TODO: define a loss function\n",
    "\n",
    "    for epoch in trange(1, epochs + 1, leave=False):\n",
    "        model.train()\n",
    "        for data in tqdm(train_loader, leave=False):\n",
    "            x, edge_index, batch, y = data.x, data.edge_index, data.batch, data.y\n",
    "            model.zero_grad()\n",
    "            preds = model(x, edge_index, batch)\n",
    "            loss = loss_fn(preds, y.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # validation loop\n",
    "        preds = predict(model, valid_loader)\n",
    "        df_logs = pd.concat([df_logs, pd.DataFrame(\n",
    "            {'epoch': epoch,\n",
    "             'preds': preds.flatten(),\n",
    "             'mode': 'valid'\n",
    "        }, index=range(len(preds.flatten())))], ignore_index=True)\n",
    "    \n",
    "    return model, df_logs\n",
    "\n",
    "\n",
    "def predict(model, test_loader):\n",
    "    # evaluation loop\n",
    "    model.eval()\n",
    "    preds_batches = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            \n",
    "            preds = model(x, edge_index, batch)\n",
    "            preds_batches.append(preds.cpu().detach().numpy())\n",
    "    preds = np.concatenate(preds_batches)\n",
    "    return preds\n",
    "\n",
    "\n",
    "# training\n",
    "model, df_logs = train(train_loader, valid_loader, df_logs)\n",
    "\n",
    "# evaluation\n",
    "predictions = predict(model, test_loader)\n",
    "df_logs = pd.concat([df_logs, pd.DataFrame({\n",
    "    'epoch': -1,\n",
    "    'preds': predictions.flatten(),\n",
    "    'mode': 'test'\n",
    "}, index=range(len(predictions.flatten())))], ignore_index=True)\n",
    "\n",
    "rmse_score = rmse(y_test, predictions.flatten())\n",
    "\n",
    "print(f'RMSE = {rmse_score:.2f}')\n",
    "assert rmse_score < 1.4, \"It should be possible to obtain RMSE lower than 1.4\"\n",
    "print('Looks OK!')\n",
    "df_logs.to_csv('training_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bd2dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rmse_np(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).flatten()\n",
    "    y_pred = np.asarray(y_pred).flatten()\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "def mae_np(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).flatten()\n",
    "    y_pred = np.asarray(y_pred).flatten()\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def predict_with_targets(model, loader):\n",
    "    model.eval()\n",
    "    preds_batches = []\n",
    "    y_batches = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, leave=False):\n",
    "            x, edge_index, batch, y = data.x, data.edge_index, data.batch, data.y\n",
    "            preds = model(x, edge_index, batch)\n",
    "            preds_batches.append(preds.cpu().numpy())\n",
    "            y_batches.append(y.cpu().numpy())\n",
    "    preds = np.concatenate(preds_batches).flatten()\n",
    "    y_true = np.concatenate(y_batches).flatten()\n",
    "    return y_true, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537a526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_run(train_loader, valid_loader, hidden_size=256, lr=1e-3, epochs=30, weight_decay=0.0, dropout=0.0, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    model = GraphNeuralNetwork(hidden_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in trange(1, epochs + 1, leave=False):\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for data in tqdm(train_loader, leave=False):\n",
    "            x, edge_index, batch, y = data.x, data.edge_index, data.batch, data.y\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x, edge_index, batch)\n",
    "            loss = loss_fn(preds, y.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        train_loss = float(np.mean(losses))\n",
    "\n",
    "        # walidacja: RMSE + MAE\n",
    "        y_valid, preds_valid = predict_with_targets(model, valid_loader)\n",
    "        valid_rmse = rmse_np(y_valid, preds_valid)\n",
    "        valid_mae = mae_np(y_valid, preds_valid)\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"valid_rmse\": valid_rmse,\n",
    "            \"valid_mae\": valid_mae\n",
    "        })\n",
    "\n",
    "    return model, pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1318b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN 1: hidden=64, lr=0.001, epochs=15, wd=0.0, seed=42 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataLoader found invalid type: '<class 'numpy.ndarray'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m run_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== RUN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: hidden=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, wd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, seed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m model, history_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m best_row \u001b[38;5;241m=\u001b[39m history_df\u001b[38;5;241m.\u001b[39mloc[history_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39midxmin()]\n\u001b[1;32m     33\u001b[0m best_valid_rmse \u001b[38;5;241m=\u001b[39m best_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mtrain_one_run\u001b[0;34m(train_loader, valid_loader, hidden_size, lr, epochs, weight_decay, dropout, seed)\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     13\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     16\u001b[0m     x, edge_index, batch, y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch, data\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mldd23/lib/python3.9/site-packages/torch_geometric/loader/dataloader.py:49\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)]\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader found invalid type: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(elem)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: DataLoader found invalid type: '<class 'numpy.ndarray'>'"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"hidden_size\": [64, 128, 256, 512],\n",
    "    \"lr\": [1e-3, 5e-4, 1e-4],\n",
    "    \"epochs\": [15],  # moesz da 30\n",
    "    \"weight_decay\": [0.0, 1e-4, 1e-3],\n",
    "    \"seed\": [42]\n",
    "}\n",
    "\n",
    "results = []\n",
    "all_histories = []\n",
    "\n",
    "run_id = 0\n",
    "\n",
    "for hidden_size in param_grid[\"hidden_size\"]:\n",
    "    for lr in param_grid[\"lr\"]:\n",
    "        for epochs in param_grid[\"epochs\"]:\n",
    "            for wd in param_grid[\"weight_decay\"]:\n",
    "                for seed in param_grid[\"seed\"]:\n",
    "                    run_id += 1\n",
    "                    print(f\"\\n=== RUN {run_id}: hidden={hidden_size}, lr={lr}, epochs={epochs}, wd={wd}, seed={seed} ===\")\n",
    "\n",
    "                    model, history_df = train_one_run(\n",
    "                        train_loader=train_loader,\n",
    "                        valid_loader=valid_loader,\n",
    "                        hidden_size=hidden_size,\n",
    "                        lr=lr,\n",
    "                        epochs=epochs,\n",
    "                        weight_decay=wd,\n",
    "                        seed=seed\n",
    "                    )\n",
    "\n",
    "                    best_row = history_df.loc[history_df[\"valid_rmse\"].idxmin()]\n",
    "                    best_valid_rmse = best_row[\"valid_rmse\"]\n",
    "                    best_epoch = int(best_row[\"epoch\"])\n",
    "\n",
    "                    results.append({\n",
    "                        \"run_id\": run_id,\n",
    "                        \"hidden_size\": hidden_size,\n",
    "                        \"lr\": lr,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"weight_decay\": wd,\n",
    "                        \"seed\": seed,\n",
    "                        \"best_valid_rmse\": best_valid_rmse,\n",
    "                        \"best_epoch\": best_epoch\n",
    "                    })\n",
    "\n",
    "                    history_df[\"run_id\"] = run_id\n",
    "                    history_df[\"hidden_size\"] = hidden_size\n",
    "                    history_df[\"lr\"] = lr\n",
    "                    history_df[\"weight_decay\"] = wd\n",
    "                    all_histories.append(history_df)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"best_valid_rmse\")\n",
    "histories_df = pd.concat(all_histories, ignore_index=True)\n",
    "\n",
    "display(results_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af833a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_cfg \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m      2\u001b[0m best_cfg\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "best_cfg = results_df.iloc[0].to_dict()\n",
    "best_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hidden = int(best_cfg[\"hidden_size\"])\n",
    "best_lr = float(best_cfg[\"lr\"])\n",
    "best_wd = float(best_cfg[\"weight_decay\"])\n",
    "\n",
    "final_model, final_history = train_one_run(\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    hidden_size=best_hidden,\n",
    "    lr=best_lr,\n",
    "    epochs=30,           # docelowo wicej\n",
    "    weight_decay=best_wd,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "display(final_history.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0acdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(final_history[\"epoch\"], final_history[\"train_loss\"], label=\"Train MSE\")\n",
    "plt.plot(final_history[\"epoch\"], final_history[\"valid_rmse\"], label=\"Valid RMSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.title(\"Training Curve (MSE vs RMSE)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904393ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_true, y_test_pred = predict_with_targets(final_model, test_loader)\n",
    "\n",
    "test_rmse = rmse_np(y_test_true, y_test_pred)\n",
    "test_mae = mae_np(y_test_true, y_test_pred)\n",
    "\n",
    "print(f\"TEST RMSE = {test_rmse:.3f}\")\n",
    "print(f\"TEST MAE  = {test_mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test_true, y_test_pred, alpha=0.4)\n",
    "minv = min(y_test_true.min(), y_test_pred.min())\n",
    "maxv = max(y_test_true.max(), y_test_pred.max())\n",
    "plt.plot([minv, maxv], [minv, maxv])  # linia idealna\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Predicted vs True (Test)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138918c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_test_pred - y_test_true\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(errors, bins=40)\n",
    "plt.xlabel(\"Prediction Error (pred - true)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Error Distribution (Test)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474be4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_analysis = pd.DataFrame({\n",
    "    \"y_true\": y_test_true,\n",
    "    \"y_pred\": y_test_pred,\n",
    "    \"error\": y_test_pred - y_test_true,\n",
    "    \"abs_error\": np.abs(y_test_pred - y_test_true)\n",
    "})\n",
    "\n",
    "display(df_test_analysis.sort_values(\"abs_error\", ascending=False).head(15))\n",
    "display(df_test_analysis.sort_values(\"abs_error\", ascending=True).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(results_df[\"hidden_size\"], results_df[\"best_valid_rmse\"], alpha=0.6)\n",
    "plt.xlabel(\"Hidden size\")\n",
    "plt.ylabel(\"Best Valid RMSE\")\n",
    "plt.title(\"Effect of Hidden Size on Valid RMSE\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(np.log10(results_df[\"lr\"]), results_df[\"best_valid_rmse\"], alpha=0.6)\n",
    "plt.xlabel(\"log10(lr)\")\n",
    "plt.ylabel(\"Best Valid RMSE\")\n",
    "plt.title(\"Effect of Learning Rate on Valid RMSE\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"hyperparam_search_results.csv\", index=False)\n",
    "histories_df.to_csv(\"hyperparam_search_histories.csv\", index=False)\n",
    "final_history.to_csv(\"final_training_history.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"- hyperparam_search_results.csv\")\n",
    "print(\"- hyperparam_search_histories.csv\")\n",
    "print(\"- final_training_history.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldd23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
